# -*- coding: utf-8 -*-
"""FP Datasains Prediksi penyakit Kardiovaskular

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xGq0xsvmCHXNX4mrv9Nh-9srGCHMj4VQ
"""



# -----------------------------------
# 1. Install XGBoost (jika belum)
# ----------------------------------

# -----------------------------------
# 2. Import Library
# -----------------------------------
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score

# -----------------------------------
# 3. Load Dataset
# Upload file "cardio_train.csv" via panel di kiri â†’ Files
# atau gunakan file bawaan jika sudah diupload
# -----------------------------------
df = pd.read_csv("/content/cardio_train.csv", sep=';')

# -----------------------------------
# 4. Pra-Pemrosesan
# -----------------------------------
df.drop(columns=['id'], inplace=True)
df['age'] = (df['age'] / 365).astype(int)  # konversi umur ke tahun

# Sampling 15000 data agar ringan (opsional)


# -----------------------------------
# 5. EDA Singkat
# -----------------------------------
plt.figure(figsize=(10, 7))
sns.heatmap(df_sample.corr(), annot=True, fmt='.2f', cmap='coolwarm')
plt.title("Korelasi antar Fitur")
plt.show()

sns.countplot(x='cardio', data=df_sample)
plt.title("Distribusi Target (cardio)")
plt.show()

# -----------------------------------
# 6. Split dan Scaling
# -----------------------------------
X = df_sample.drop('cardio', axis=1)
y = df_sample['cardio']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# -----------------------------------
# 7. Random Forest Classifier
# -----------------------------------
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train_scaled, y_train)
y_pred_rf = rf.predict(X_test_scaled)

print("ðŸ“Š Random Forest:")
print(classification_report(y_test, y_pred_rf))
print("Akurasi:", accuracy_score(y_test, y_pred_rf))
print("ROC AUC:", roc_auc_score(y_test, y_pred_rf))

# -----------------------------------
# 8. XGBoost Classifier
# -----------------------------------
xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)
xgb.fit(X_train_scaled, y_train)
y_pred_xgb = xgb.predict(X_test_scaled)

print("\nðŸ“Š XGBoost:")
print(classification_report(y_test, y_pred_xgb))
print("Akurasi:", accuracy_score(y_test, y_pred_xgb))
print("ROC AUC:", roc_auc_score(y_test, y_pred_xgb))

# -----------------------------------
# 9. Confusion Matrix
# -----------------------------------
fig, axs = plt.subplots(1, 2, figsize=(12, 5))

sns.heatmap(confusion_matrix(y_test, y_pred_rf), annot=True, fmt='d', ax=axs[0], cmap='Blues')
axs[0].set_title("Confusion Matrix - Random Forest")

sns.heatmap(confusion_matrix(y_test, y_pred_xgb), annot=True, fmt='d', ax=axs[1], cmap='Oranges')
axs[1].set_title("Confusion Matrix - XGBoost")

plt.show()

df.info()

df.isnull().sum()

# Melihat tipe data setiap kolom
print("Tipe Data Setiap Kolom:")
print(df.dtypes)

# Melihat statistik deskriptif
print("\nStatistik Deskriptif:")
display(df.describe())

# streamlit_app.py
import streamlit as st
import numpy as np
import joblib

model = joblib.load('best_model.pkl')
scaler = joblib.load('scaler.pkl')

st.title("Prediksi Penyakit Kardiovaskular")

age = st.slider("Umur (tahun)", 30, 80, 50)
height = st.number_input("Tinggi Badan (cm)", 100, 220, 160)
weight = st.number_input("Berat Badan (kg)", 30, 200, 70)
ap_hi = st.number_input("Tekanan Darah Sistolik", 80, 200, 120)
ap_lo = st.number_input("Tekanan Darah Diastolik", 50, 150, 80)
cholesterol = st.selectbox("Kolesterol", [1, 2, 3])
gluc = st.selectbox("Glukosa", [1, 2, 3])
gender = st.radio("Jenis Kelamin", [1, 2])  # 1=Wanita, 2=Pria
smoke = st.radio("Perokok?", [0, 1])
alco = st.radio("Alkohol?", [0, 1])
active = st.radio("Aktif secara fisik?", [0, 1])

if st.button("Prediksi"):
    input_data = np.array([[age, gender, height, weight, ap_hi, ap_lo,
                            cholesterol, gluc, smoke, alco, active]])
    input_scaled = scaler.transform(input_data)
    prediction = model.predict(input_scaled)

    if prediction[0] == 1:
        st.error("Pasien berisiko penyakit kardiovaskular.")
    else:
        st.success("Pasien tidak berisiko penyakit kardiovaskular.")

import joblib

# Save the best model (XGBoost in this case)
joblib.dump(xgb, 'best_model.pkl')

# Save the scaler
joblib.dump(scaler, 'scaler.pkl')

print("Model dan scaler berhasil disimpan.")
